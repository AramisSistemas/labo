#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60 && cliente_vip=0) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "./labo/exp/" )
dir.create( "./labo/exp/KA2001" )
fwrite( entrega,
file= "./labo/exp/KA2001/K101_001.csv",
sep= "," )
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  80,     #minima cantidad de registros para que se haga el split
minbucket=  1,     #tamaño minimo de una hoja
maxdepth=   4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#cargo los datos de 202011, que es donde voy a APLICAR el modelo
dapply  <- fread("./datasets/paquete_premium_202101.csv")
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo, dapply , type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60 && cliente_vip=0 && prob_baja1 > 1/60) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "./labo/exp/" )
dir.create( "./labo/exp/KA2001" )
fwrite( entrega,
file= "./labo/exp/KA2001/K101_001.csv",
sep= "," )
View(dtrain)
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -0.3,   #esto significa no limitar la complejidad de los splits
minsplit=  80,     #minima cantidad de registros para que se haga el split
minbucket=  1,     #tamaño minimo de una hoja
maxdepth=   4 )    #profundidad maxima del arbol
#grafico el arbol
prp(modelo, extra=101, digits=5, branch=1, type=4, varlen=0, faclen=0)
#cargo los datos de 202011, que es donde voy a APLICAR el modelo
dapply  <- fread("./datasets/paquete_premium_202101.csv")
#aplico el modelo a los datos nuevos
prediccion  <- predict( modelo, dapply , type = "prob")
#agrego a dapply una columna nueva que es la probabilidad de BAJA+2
dapply[ , prob_baja2 := prediccion[, "BAJA+2"] ]
#solo le envio estimulo a los registros con probabilidad de BAJA+2 mayor  a  1/60
dapply[ , Predicted  := as.numeric(prob_baja2 > 1/60 && cliente_vip=0 && prob_baja1 > 1/60 && cliente_antiguedad < 100 ) ]
#genero un dataset con las dos columnas que me interesan
entrega  <- dapply[   , list(numero_de_cliente, Predicted) ] #genero la salida
#genero el archivo para Kaggle
#creo la carpeta donde va el experimento
dir.create( "./labo/exp/" )
dir.create( "./labo/exp/KA2001" )
fwrite( entrega,
file= "./labo/exp/KA2001/K101_001.csv",
sep= "," )
require("data.table")
require("rpart")
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=101107  )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
#Aqui se debe poner la carpeta de la computadora local
setwd("D:\\gdrive\\Austral2022R\\")   #Establezco el Working Directory
dataset  <- fread("./datasets/paquete_premium_202011.csv")
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= 102191 )  #Cambiar por la primer semilla de cada uno !
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control=  param_basicos )  #aqui van los parametros
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#agrego una columna que es la de las ganancias
dataset[  , ganancia :=  ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ) ]
#para testing agrego la probabilidad
dataset[ fold==2 , prob_baja2 := prediccion[, "BAJA+2"] ]
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2 & prob_baja2 >  1/60, sum(ganancia) ]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
cat( ganancia_test_normalizada )
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677, 102701, 101107, 104701, 101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("D:\\gdrive\\Austral2022R\\")   #Establezco el Working Directory
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677, 102701, 101107, 104701, 101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#Un solo llamado, con la semilla 17
ArbolEstimarGanancia( 17, param_basicos )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677, 102701, 101107, 104701, 101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#Un solo llamado, con la semilla 17
ArbolEstimarGanancia( 17, param_basicos )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677, 102701, 101107, 104701, 101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
install.packages("parallel")
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677, 102701, 101107, 104701, 101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#Un solo llamado, con la semilla 17
ArbolEstimarGanancia( 17, param_basicos )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677,102701,101107,104701,101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#Un solo llamado, con la semilla 17
ArbolEstimarGanancia( 17, param_basicos )
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677,102701,101107,104701,101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
View(particionar)
View(dtrain)
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z222_traintest_montecarlo.r', encoding = 'UTF-8', echo=TRUE)
rm( list=ls() )  #Borro todos los objetos
gc()   #Garbage Collection
require("data.table")
require("rpart")
require("parallel")
ksemillas  <- c(104677,102701,101107,104701,101021) #reemplazar por las propias semillas
particionar  <- function( data,  division, agrupa="",  campo="fold", start=1, seed=NA )
{
if( !is.na(seed) )   set.seed( seed )
bloque  <- unlist( mapply(  function(x,y) { rep( y, x )} ,   division,  seq( from=start, length.out=length(division) )  ) )
data[ , (campo) :=  sample( rep( bloque, ceiling(.N/length(bloque))) )[1:.N],
by= agrupa ]
}
ArbolEstimarGanancia  <- function( semilla, param_basicos )
{
#particiono estratificadamente el dataset
particionar( dataset, division=c(70,30), agrupa="clase_ternaria", seed= semilla )  #Cambiar por la primer semilla de cada uno !
#genero el modelo
modelo  <- rpart("clase_ternaria ~ .",     #quiero predecir clase_ternaria a partir del resto
data= dataset[ fold==1],  #fold==1  es training,  el 70% de los datos
xval= 0,
control= param_basicos )  #aqui van los parametros del arbol
#aplico el modelo a los datos de testing
prediccion  <- predict( modelo,   #el modelo que genere recien
dataset[ fold==2],  #fold==2  es testing, el 30% de los datos
type= "prob") #type= "prob"  es que devuelva la probabilidad
#prediccion es una matriz con TRES columnas, llamadas "BAJA+1", "BAJA+2"  y "CONTINUA"
#cada columna es el vector de probabilidades
#calculo la ganancia en testing  qu es fold==2
ganancia_test  <- dataset[ fold==2,
sum( ifelse( prediccion[, "BAJA+2"]  >  1/60,
ifelse( clase_ternaria=="BAJA+2", 59000, -1000 ),
0 ) )]
#escalo la ganancia como si fuera todo el dataset
ganancia_test_normalizada  <-  ganancia_test / 0.3
return( ganancia_test_normalizada )
}
#Aqui se debe poner la carpeta de la computadora local
setwd("E:\\Documents\\Maestria\\LabImplementacion")  #Establezco el Working Directory
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
dtrain
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
param_basicos  <- list( "cp"=         0,  #complejidad minima
"minsplit"=  10,  #minima cantidad de registros en un nodo para hacer el split
"minbucket"=  2,  #minima cantidad de registros en una hoja
"maxdepth"=  10 ) #profundidad máxima del arbol
#Un solo llamado, con la semilla 17
ArbolEstimarGanancia( 17, param_basicos )
#la funcion mcmapply  llama a la funcion ArbolEstimarGanancia  tantas veces como valores tenga el vector  ksemillas
ganancias  <- mcmapply( ArbolEstimarGanancia,
ksemillas,   #paso el vector de semillas, que debe ser el primer parametro de la funcion ArbolEstimarGanancia
MoreArgs= list( param_basicos),  #aqui paso el segundo parametro
SIMPLIFY= FALSE,
mc.cores= 1 )  #se puede subir a 5 si posee Linux o Mac OS
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z222_traintest_montecarlo.r', encoding = 'UTF-8', echo=TRUE)
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z222_traintest_montecarlo.r', encoding = 'UTF-8', echo=TRUE)
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z222_traintest_montecarlo.r', encoding = 'UTF-8', echo=TRUE)
cat(mean( unlist(ganancias) ))
cat(mean( unlist(ganancias) ))
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z222_traintest_montecarlo.r', encoding = 'UTF-8', echo=TRUE)
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z231_mejormodelo.r', encoding = 'UTF-8', echo=TRUE)
source('E:/Documents/Maestria/LabImplementacion/labo/src/rpart/z231_mejormodelo.r', encoding = 'UTF-8', echo=TRUE)
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -1,   #esto significa no limitar la complejidad de los splits
minsplit=  300,     #minima cantidad de registros para que se haga el split
minbucket=  100,     #tamaño minimo de una hoja
maxdepth=   0 )    #profundidad maxima del arbol
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de SU computadora local
setwd("D:\\gdrive\\Austral2022R\\")  #Establezco el Working Directory
#cargo las librerias que necesito
require("data.table")
require("rpart")
require("rpart.plot")
#Aqui se debe poner la carpeta de SU computadora local
setwd("D:\\gdrive\\Austral2022R\\")  #Establezco el Working Directory
#cargo los datos de 202011 que es donde voy a ENTRENAR el modelo
dtrain  <- fread("./datasets/paquete_premium_202011.csv")
#genero el modelo,  aqui se construye el arbol
modelo  <- rpart("clase_ternaria ~ .",  #quiero predecir clase_ternaria a partir de el resto de las variables
data = dtrain,
xval=0,
cp=        -1,   #esto significa no limitar la complejidad de los splits
minsplit=  300,     #minima cantidad de registros para que se haga el split
minbucket=  100,     #tamaño minimo de una hoja
maxdepth=   0 )    #profundidad maxima del arbol
View(dataset)
View(dataset)
View(ArbolesMontecarlo)
